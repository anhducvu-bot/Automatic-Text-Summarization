{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rouge compares n-gram of human summarization vs. model. Different Rouges are as follows:\n",
    "\n",
    "•\tROUGE-N: Overlap of N-grams[2] between the system and reference summaries.\n",
    "\n",
    "•\tROUGE-1 refers to the overlap of unigram (each word) between the system and reference summaries.\n",
    "\n",
    "•\tROUGE-2 refers to the overlap of bigrams2 between the system and reference summaries.\n",
    "\n",
    "•\tROUGE-L: Longest Common Subsequence (LCS)[3] based statistics. Longest common subsequence problem takes into account sentence level structure similarity naturally and identifies longest co-occurring in sequence n-grams automatically.\n",
    "\n",
    "•\tROUGE-W: Weighted LCS-based statistics that favors consecutive LCSes .\n",
    "\n",
    "•\tROUGE-S: Skip-bigram[3] based co-occurrence statistics. Skip-bigram is any pair of words in their sentence order.\n",
    "\n",
    "•\tROUGE-SU: Skip-bigram plus unigram-based co-occurrence statistics.\n",
    "\n",
    "In our papers it is looking at Rouge-1 (unigram) F1, Rouge-2 (bigram) F1, Rouge-L F1 (longest common sub-sequence) \n",
    "\n",
    "If a score is ever identified as rouge without identifying its metric assume it is refering to the F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': Score(precision=0.75, recall=0.6666666666666666, fmeasure=0.7058823529411765),\n",
       " 'rouge2': Score(precision=0.2857142857142857, recall=0.25, fmeasure=0.26666666666666666),\n",
       " 'rougeL': Score(precision=0.625, recall=0.5555555555555556, fmeasure=0.5882352941176471)}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple Rouge\n",
    "from rouge_score import rouge_scorer\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "scores = scorer.score('The quick brown fox jumps over the lazy dog',\n",
    "                      'The quick brown dog jumps on the log.')\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rouge with Pegasus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8af6745e39493f91cdb9c0e653604b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2275327883.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepping pegasus \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/pegasus-cnn_dailymail\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/pegasus-cnn_dailymail\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset cnn_dailymail/3.0.0 (download: 558.32 MiB, generated: 1.28 GiB, post-processed: Unknown size, total: 1.82 GiB) to /Users/acmonnin/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563eda6b8b624473ae9dea4bcc9f19de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea78c5f360e84f30b70b94eeb6aebaa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/159M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437d4df8f29144cc8a5d53fc32d50c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/376M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11034bf0efa447ac96d72dc656a55565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/572k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d933f0f8bea14356b13bcccda3326feb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/12.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21630837465043b2aed28a36908d2475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/661k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd50e273e534b95803e1ed1aef853b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb623e9df61b46519d8f1262c6bbe09c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ac7e1812e64f19a2eb646fffbde372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8beb778fda1d414ba46adb1f46177988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cnn_dailymail downloaded and prepared to /Users/acmonnin/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79096ddbeb6f4afe82f0468eca0f1db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepping the data\n",
    "raw_datasets = load_dataset(\"cnn_dailymail\", '3.0.0')\n",
    "# metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The country\\'s consumer watchdog has taken Apple to court for false advertising because the tablet computer does not work on Australia\\'s 4G network.\\nApple\\'s lawyers said they were willing to publish a clarification.\\nHowever the company does not accept that it misled customers.\\nThe Australian Competition and Consumer Commission (ACCC) said on Tuesday: \"Apple\\'s recent promotion of the new \\'iPad with wi-fi + 4G\\' is misleading because it represents to Australian consumers that the product can, with a sim card, connect to a 4G mobile data network in Australia, when this is not the case.\"\\nThe watchdog then lodged a complaint at the Federal Court in Melbourne.\\nAt a preliminary hearing, Apple lawyer Paul Anastassiou said Apple had never claimed the device would work fully on the current 4G network operated by Telstra.\\nApple says the new iPad works on what is globally accepted to be a 4G network.\\nThe matter will go to a full trial on 2 May.\\nThe Apple iPad\\'s third version went on sale earlier this month, with Australia the first country where it was available.\\nShoppers lined up by the hundreds at Apple stores on opening day and the company said it had been its strongest iPad launch to date.\\nThe ACCC said it was seeking an injunction on sales as well as a financial penalty against Apple, corrective advertising and refunds to consumers.\\nOn its website, Apple does state that 4G LTE is only supported on selected networks in the US and Canada.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = raw_datasets['validation'][0]['document']\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this case we are just using a single document but we can pass multiple to the tokenizer\n",
    "batch = tokenizer(doc, truncation=True, padding='longest', return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,  1814,   131,   116,  5113,   243,   157,   195,  2747,   112,\n",
       "          5442,   114, 19259,   110,   107,   106,   159,   301,   358,   146,\n",
       "          2217,   120,   126, 45520,   527,   110,   107,   106,   159,   841,\n",
       "           138,   275,   112,   114,   357,  2498,   124,   280,   913,   110,\n",
       "           107,     1]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated = model.generate(**batch)\n",
    "translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary from pegasus:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"Apple's lawyers said they were willing to publish a clarification.<n>The company does not accept that it misled customers.<n>The matter will go to a full trial on 2 May.\"]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting from tokens back into strings\n",
    "summary=tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "print(\"Summary from pegasus:\")\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary from human reader:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'US technology firm Apple has offered to refund Australian customers who felt misled about the 4G capabilities of the new iPad.'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary as provided by a human reader\n",
    "golden_summary=raw_datasets['validation'][0]['summary']\n",
    "print(\"Summary from human reader:\")\n",
    "golden_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': Score(precision=0.2857142857142857, recall=0.18181818181818182, fmeasure=0.2222222222222222),\n",
       " 'rouge2': Score(precision=0.0, recall=0.0, fmeasure=0.0),\n",
       " 'rougeL': Score(precision=0.19047619047619047, recall=0.12121212121212122, fmeasure=0.14814814814814814)}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True) # These are the metrics used in our paper\n",
    "scores = scorer.score(summary[0], golden_summary)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options for Metric Calculation\n",
    "load_metrics from datasets package - This will likely scale the best\n",
    "\n",
    "rouge_scoreer - Great for getting a sense of how rouge works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
